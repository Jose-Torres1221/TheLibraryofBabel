{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility for PyTorch and NumPy.\n",
        "    Args:\n",
        "        seed_value (int): The seed value to set for random number generators.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "    # Additional steps for deterministic behavior\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set the seed\n",
        "set_seed(42)  # You can replace 42 with any other seed value of your choice"
      ],
      "metadata": {
        "id": "4MaijIVRrFh-"
      },
      "id": "4MaijIVRrFh-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load model directly\n",
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\",device=0)\n",
        "ftModelPath = './fine_tuned_BART_summarization'\n",
        "ftSummarizer = pipeline(\"summarization\",model=ftModelPath,device=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FptfqHI4Js9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733098080026,
          "user_tz": 360,
          "elapsed": 9930,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "72cb3ea3-828f-4234-8cb7-dfe6876b80e8"
      },
      "id": "2FptfqHI4Js9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_summary_from_lm(rawText, model):\n",
        "  max_length = round(len(rawText)*0.2)\n",
        "  min_length = round(len(rawText)*0.02)\n",
        "  output = model(rawText,max_length=max_length,min_length=min_length, do_sample=False)\n",
        "  return output[0]['summary_text']\n"
      ],
      "metadata": {
        "id": "Ymq0v5CMFQH7"
      },
      "id": "Ymq0v5CMFQH7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "esAbstract = pd.read_csv('papers_EStoEN.csv')['abstract_translated']\n",
        "jpAbstract = pd.read_csv('papers_JPtoEN.csv')['abstract_translated']"
      ],
      "metadata": {
        "id": "7GxAEdfezVE9"
      },
      "id": "7GxAEdfezVE9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BART_summaryList_ES = []\n",
        "for abstract in esAbstract:\n",
        "  BART_summaryList_ES.append(get_summary_from_lm(abstract, summarizer))\n",
        "\n",
        "BART_summaryList_JP = []\n",
        "for abstract in jpAbstract:\n",
        "  BART_summaryList_JP.append(get_summary_from_lm(abstract, summarizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Eutcq4P76FW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733098097586,
          "user_tz": 360,
          "elapsed": 17564,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "301dba1b-90c1-4da8-8c73-9d71e28485be"
      },
      "id": "-Eutcq4P76FW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 259, but your input_length is only 233. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=116)\n",
            "Your max_length is set to 241, but your input_length is only 202. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=101)\n",
            "Your max_length is set to 74, but your input_length is only 72. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n",
            "Your max_length is set to 181, but your input_length is only 167. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=83)\n",
            "Your max_length is set to 302, but your input_length is only 282. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=141)\n",
            "Your max_length is set to 244, but your input_length is only 208. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=104)\n",
            "Your max_length is set to 96, but your input_length is only 91. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n",
            "Your max_length is set to 106, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Your max_length is set to 202, but your input_length is only 193. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_BART_summaryList_ES = []\n",
        "for abstract in esAbstract:\n",
        "  ft_BART_summaryList_ES.append(get_summary_from_lm(abstract, ftSummarizer))\n",
        "\n",
        "ft_BART_summaryList_JP = []\n",
        "for abstract in jpAbstract:\n",
        "  ft_BART_summaryList_JP.append(get_summary_from_lm(abstract, ftSummarizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwpt0n8k5CLV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733098111493,
          "user_tz": 360,
          "elapsed": 13909,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e2581052-c8fd-4635-e77b-136183d58834"
      },
      "id": "fwpt0n8k5CLV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 259, but your input_length is only 233. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=116)\n",
            "Your max_length is set to 241, but your input_length is only 202. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=101)\n",
            "Your max_length is set to 74, but your input_length is only 72. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n",
            "Your max_length is set to 181, but your input_length is only 167. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=83)\n",
            "Your max_length is set to 302, but your input_length is only 282. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=141)\n",
            "Your max_length is set to 244, but your input_length is only 208. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=104)\n",
            "Your max_length is set to 96, but your input_length is only 91. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=45)\n",
            "Your max_length is set to 106, but your input_length is only 96. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=48)\n",
            "Your max_length is set to 202, but your input_length is only 193. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultDictES = {\n",
        "    \"BART\": BART_summaryList_ES,\n",
        "    \"BART_ft\":ft_BART_summaryList_ES\n",
        "}\n",
        "\n",
        "resultDictJP = {\n",
        "    \"BART\":BART_summaryList_JP,\n",
        "    \"BART_ft\":ft_BART_summaryList_JP\n",
        "}\n",
        "\n",
        "pd.DataFrame(resultDictES).to_csv(\"summarization_BART_pipeline_ES.csv\")\n",
        "pd.DataFrame(resultDictJP).to_csv(\"summarization_BART_pipeline_JP.csv\")"
      ],
      "metadata": {
        "id": "si1tUnEa87PR"
      },
      "id": "si1tUnEa87PR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "runModel_casaInternational_BART_pipeline.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}