{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install rouge-score\n",
        "!pip install transformers\n",
        "!pip install bert-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yh5NmUt70oCR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733354295563,
          "user_tz": 360,
          "elapsed": 18335,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f2fdf448-03d7-4e04-d43c-33098200b4ad"
      },
      "id": "Yh5NmUt70oCR",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.6)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=95f300684f4ce1ba9b830fdfe9a2b30bdf3f35c2c9815dd58f2eb54478ebdb45\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting bert-score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.5.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.46.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.66.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.26.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.20.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bert-score\n",
            "Successfully installed bert-score-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import BERTScorer\n",
        "import pprint\n",
        "import math\n",
        "\n",
        "# Ensure required NLTK data is available\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "def scoreCalculator(referenceText,hypothesisText):\n",
        "    if type(hypothesisText) != str:\n",
        "      print(\"Empty string entered\")\n",
        "      hypothesisText = \"\"\n",
        "    # Preprocess: Tokenize for BLEU and METEOR scores\n",
        "    hypothesisText_tokens = word_tokenize(hypothesisText)\n",
        "    referenceText_tokens = word_tokenize(referenceText)\n",
        "\n",
        "    # Get BLEU score\n",
        "    BLEU = sentence_bleu([referenceText_tokens], hypothesisText_tokens)\n",
        "\n",
        "    # Get METEOR score\n",
        "    METEOR = meteor_score([referenceText_tokens], hypothesisText_tokens)\n",
        "\n",
        "    # Get ROUGE score\n",
        "    ROUGEscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    ROUGE = ROUGEscorer.score(referenceText, hypothesisText)\n",
        "\n",
        "    # Get BERT score\n",
        "    BERTscorer = BERTScorer(model_type='bert-base-uncased', lang=\"en\", rescale_with_baseline=True)\n",
        "    BERT_P, BERT_R, BERT_F1 = BERTscorer.score([hypothesisText], [referenceText])\n",
        "\n",
        "    # Return dict and print\n",
        "    scoreDict = {\n",
        "        \"BLEU\": round(BLEU, 2),\n",
        "        \"METEOR\": round(METEOR, 2),\n",
        "        \"ROUGE1_precision\": round(ROUGE[\"rouge1\"].precision, 2),\n",
        "        \"ROUGE1_recall\": round(ROUGE[\"rouge1\"].recall, 2),\n",
        "        \"ROUGE1_F1\": round(ROUGE[\"rouge1\"].fmeasure, 2),\n",
        "        \"ROUGE2_precision\": round(ROUGE[\"rouge2\"].precision, 2),\n",
        "        \"ROUGE2_recall\": round(ROUGE[\"rouge2\"].recall, 2),\n",
        "        \"ROUGE2_F1\": round(ROUGE[\"rouge2\"].fmeasure, 2),\n",
        "        \"ROUGEL_precision\": round(ROUGE[\"rougeL\"].precision, 2),\n",
        "        \"ROUGEL_recall\": round(ROUGE[\"rougeL\"].recall, 2),\n",
        "        \"ROUGEL_F1\": round(ROUGE[\"rougeL\"].fmeasure, 2),\n",
        "        \"BERT_precision\": round(BERT_P.item(), 2),\n",
        "        \"BERT_recall\": round(BERT_R.item(), 2),\n",
        "        \"BERT_F1\": round(BERT_F1.item(), 2),\n",
        "    }\n",
        "\n",
        "    print(\"Score Summary:\")\n",
        "    for key, value in scoreDict.items():\n",
        "      print(f\"{key}: {value}\")\n",
        "\n",
        "    return scoreDict\n"
      ],
      "metadata": {
        "id": "iteN0cPk0vav",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733354312708,
          "user_tz": 360,
          "elapsed": 13621,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d62e129-7886-4b64-80e9-109e93b86307"
      },
      "id": "iteN0cPk0vav",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ES_hypothesis_df = pd.read_csv(\"summarization_BART_ES.csv\")\n",
        "ES_reference_df = pd.read_csv(\"csvFiles/papers_EStoEN.csv\")\n",
        "\n",
        "JP_hypothesis_df = pd.read_csv(\"summarization_BART_JP.csv\")\n",
        "JP_reference_df = pd.read_csv(\"csvFiles/papers_JPtoEN.csv\")"
      ],
      "metadata": {
        "id": "RaDzLrEnzwfs"
      },
      "id": "RaDzLrEnzwfs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ES_referenceText = ES_reference_df['contribution_translated']\n",
        "JP_referenceText = JP_reference_df['contribution_translated']\n",
        "\n",
        "ES_hypothesis_BART = ES_hypothesis_df['BART']\n",
        "ES_hypothesis_BART_ft = ES_hypothesis_df['BART_ft']\n",
        "\n",
        "JP_hypothesis_BART = JP_hypothesis_df['BART']\n",
        "JP_hypothesis_BART_ft = JP_hypothesis_df['BART_ft']"
      ],
      "metadata": {
        "id": "OmgxiiDR0qY9"
      },
      "id": "OmgxiiDR0qY9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluator(referenceSeries,hypothesisSeries):\n",
        "  assert len(referenceSeries) == len(hypothesisSeries)\n",
        "\n",
        "  dfSeed = []\n",
        "  for i in range(len(referenceSeries)):\n",
        "    scores = scoreCalculator(referenceSeries[i],hypothesisSeries[i])\n",
        "    dfSeed.append(scores)\n",
        "\n",
        "  df = pd.DataFrame(dfSeed)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "oY9RhPSM1R2A"
      },
      "id": "oY9RhPSM1R2A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_JP_BART = evaluator(JP_referenceText,JP_hypothesis_BART)\n",
        "df_JP_BART_ft = evaluator(JP_referenceText,JP_hypothesis_BART_ft)\n",
        "\n",
        "df_ES_BART = evaluator(ES_referenceText,ES_hypothesis_BART)\n",
        "df_ES_BART_ft = evaluator(ES_referenceText,ES_hypothesis_BART_ft)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6a0uwXN2ArA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1733098267699,
          "user_tz": 360,
          "elapsed": 24279,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4c88b6d0-7ed7-4ab7-f57e-13fdd08f93ad"
      },
      "id": "V6a0uwXN2ArA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.1\n",
            "METEOR: 0.3\n",
            "ROUGE1_precision: 0.65\n",
            "ROUGE1_recall: 0.38\n",
            "ROUGE1_F1: 0.48\n",
            "ROUGE2_precision: 0.31\n",
            "ROUGE2_recall: 0.18\n",
            "ROUGE2_F1: 0.22\n",
            "ROUGEL_precision: 0.49\n",
            "ROUGEL_recall: 0.29\n",
            "ROUGEL_F1: 0.36\n",
            "BERT_precision: 0.48\n",
            "BERT_recall: 0.44\n",
            "BERT_F1: 0.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.26\n",
            "ROUGE1_precision: 0.25\n",
            "ROUGE1_recall: 0.43\n",
            "ROUGE1_F1: 0.32\n",
            "ROUGE2_precision: 0.08\n",
            "ROUGE2_recall: 0.14\n",
            "ROUGE2_F1: 0.1\n",
            "ROUGEL_precision: 0.18\n",
            "ROUGEL_recall: 0.3\n",
            "ROUGEL_F1: 0.22\n",
            "BERT_precision: 0.27\n",
            "BERT_recall: 0.39\n",
            "BERT_F1: 0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.12\n",
            "ROUGE1_precision: 0.08\n",
            "ROUGE1_recall: 0.3\n",
            "ROUGE1_F1: 0.12\n",
            "ROUGE2_precision: 0.01\n",
            "ROUGE2_recall: 0.05\n",
            "ROUGE2_F1: 0.02\n",
            "ROUGEL_precision: 0.06\n",
            "ROUGEL_recall: 0.26\n",
            "ROUGEL_F1: 0.1\n",
            "BERT_precision: 0.16\n",
            "BERT_recall: 0.23\n",
            "BERT_F1: 0.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.22\n",
            "ROUGE1_precision: 0.32\n",
            "ROUGE1_recall: 0.34\n",
            "ROUGE1_F1: 0.33\n",
            "ROUGE2_precision: 0.0\n",
            "ROUGE2_recall: 0.0\n",
            "ROUGE2_F1: 0.0\n",
            "ROUGEL_precision: 0.19\n",
            "ROUGEL_recall: 0.21\n",
            "ROUGEL_F1: 0.2\n",
            "BERT_precision: 0.31\n",
            "BERT_recall: 0.37\n",
            "BERT_F1: 0.34\n",
            "Score Summary:\n",
            "BLEU: 0.07\n",
            "METEOR: 0.33\n",
            "ROUGE1_precision: 0.25\n",
            "ROUGE1_recall: 0.45\n",
            "ROUGE1_F1: 0.33\n",
            "ROUGE2_precision: 0.1\n",
            "ROUGE2_recall: 0.18\n",
            "ROUGE2_F1: 0.13\n",
            "ROUGEL_precision: 0.22\n",
            "ROUGEL_recall: 0.38\n",
            "ROUGEL_F1: 0.28\n",
            "BERT_precision: 0.33\n",
            "BERT_recall: 0.46\n",
            "BERT_F1: 0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.11\n",
            "ROUGE1_precision: 0.32\n",
            "ROUGE1_recall: 0.23\n",
            "ROUGE1_F1: 0.26\n",
            "ROUGE2_precision: 0.11\n",
            "ROUGE2_recall: 0.08\n",
            "ROUGE2_F1: 0.09\n",
            "ROUGEL_precision: 0.29\n",
            "ROUGEL_recall: 0.2\n",
            "ROUGEL_F1: 0.24\n",
            "BERT_precision: 0.43\n",
            "BERT_recall: 0.43\n",
            "BERT_F1: 0.43\n",
            "Score Summary:\n",
            "BLEU: 0.1\n",
            "METEOR: 0.52\n",
            "ROUGE1_precision: 0.27\n",
            "ROUGE1_recall: 0.7\n",
            "ROUGE1_F1: 0.39\n",
            "ROUGE2_precision: 0.16\n",
            "ROUGE2_recall: 0.42\n",
            "ROUGE2_F1: 0.23\n",
            "ROUGEL_precision: 0.17\n",
            "ROUGEL_recall: 0.45\n",
            "ROUGEL_F1: 0.25\n",
            "BERT_precision: 0.3\n",
            "BERT_recall: 0.58\n",
            "BERT_F1: 0.42\n",
            "Score Summary:\n",
            "BLEU: 0.08\n",
            "METEOR: 0.33\n",
            "ROUGE1_precision: 0.33\n",
            "ROUGE1_recall: 0.48\n",
            "ROUGE1_F1: 0.39\n",
            "ROUGE2_precision: 0.12\n",
            "ROUGE2_recall: 0.17\n",
            "ROUGE2_F1: 0.14\n",
            "ROUGEL_precision: 0.19\n",
            "ROUGEL_recall: 0.28\n",
            "ROUGEL_F1: 0.23\n",
            "BERT_precision: 0.32\n",
            "BERT_recall: 0.32\n",
            "BERT_F1: 0.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.38\n",
            "ROUGE1_precision: 0.28\n",
            "ROUGE1_recall: 0.46\n",
            "ROUGE1_F1: 0.35\n",
            "ROUGE2_precision: 0.13\n",
            "ROUGE2_recall: 0.22\n",
            "ROUGE2_F1: 0.16\n",
            "ROUGEL_precision: 0.21\n",
            "ROUGEL_recall: 0.33\n",
            "ROUGEL_F1: 0.25\n",
            "BERT_precision: 0.34\n",
            "BERT_recall: 0.39\n",
            "BERT_F1: 0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.19\n",
            "ROUGE1_precision: 0.14\n",
            "ROUGE1_recall: 0.26\n",
            "ROUGE1_F1: 0.18\n",
            "ROUGE2_precision: 0.02\n",
            "ROUGE2_recall: 0.04\n",
            "ROUGE2_F1: 0.03\n",
            "ROUGEL_precision: 0.1\n",
            "ROUGEL_recall: 0.19\n",
            "ROUGEL_F1: 0.13\n",
            "BERT_precision: 0.23\n",
            "BERT_recall: 0.2\n",
            "BERT_F1: 0.22\n",
            "Score Summary:\n",
            "BLEU: 0.43\n",
            "METEOR: 0.72\n",
            "ROUGE1_precision: 0.82\n",
            "ROUGE1_recall: 0.71\n",
            "ROUGE1_F1: 0.76\n",
            "ROUGE2_precision: 0.57\n",
            "ROUGE2_recall: 0.5\n",
            "ROUGE2_F1: 0.53\n",
            "ROUGEL_precision: 0.76\n",
            "ROUGEL_recall: 0.67\n",
            "ROUGEL_F1: 0.71\n",
            "BERT_precision: 0.78\n",
            "BERT_recall: 0.76\n",
            "BERT_F1: 0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.25\n",
            "ROUGE1_precision: 0.21\n",
            "ROUGE1_recall: 0.47\n",
            "ROUGE1_F1: 0.29\n",
            "ROUGE2_precision: 0.08\n",
            "ROUGE2_recall: 0.17\n",
            "ROUGE2_F1: 0.11\n",
            "ROUGEL_precision: 0.16\n",
            "ROUGEL_recall: 0.37\n",
            "ROUGEL_F1: 0.23\n",
            "BERT_precision: 0.24\n",
            "BERT_recall: 0.36\n",
            "BERT_F1: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.19\n",
            "ROUGE1_precision: 0.15\n",
            "ROUGE1_recall: 0.3\n",
            "ROUGE1_F1: 0.2\n",
            "ROUGE2_precision: 0.02\n",
            "ROUGE2_recall: 0.05\n",
            "ROUGE2_F1: 0.03\n",
            "ROUGEL_precision: 0.11\n",
            "ROUGEL_recall: 0.22\n",
            "ROUGEL_F1: 0.14\n",
            "BERT_precision: 0.2\n",
            "BERT_recall: 0.2\n",
            "BERT_F1: 0.2\n",
            "Score Summary:\n",
            "BLEU: 0.16\n",
            "METEOR: 0.47\n",
            "ROUGE1_precision: 0.38\n",
            "ROUGE1_recall: 0.45\n",
            "ROUGE1_F1: 0.41\n",
            "ROUGE2_precision: 0.15\n",
            "ROUGE2_recall: 0.18\n",
            "ROUGE2_F1: 0.16\n",
            "ROUGEL_precision: 0.24\n",
            "ROUGEL_recall: 0.28\n",
            "ROUGEL_F1: 0.25\n",
            "BERT_precision: 0.49\n",
            "BERT_recall: 0.51\n",
            "BERT_F1: 0.5\n",
            "Score Summary:\n",
            "BLEU: 0.18\n",
            "METEOR: 0.44\n",
            "ROUGE1_precision: 0.63\n",
            "ROUGE1_recall: 0.41\n",
            "ROUGE1_F1: 0.5\n",
            "ROUGE2_precision: 0.39\n",
            "ROUGE2_recall: 0.25\n",
            "ROUGE2_F1: 0.3\n",
            "ROUGEL_precision: 0.63\n",
            "ROUGEL_recall: 0.41\n",
            "ROUGEL_F1: 0.5\n",
            "BERT_precision: 0.59\n",
            "BERT_recall: 0.51\n",
            "BERT_F1: 0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.16\n",
            "ROUGE1_precision: 0.33\n",
            "ROUGE1_recall: 0.28\n",
            "ROUGE1_F1: 0.3\n",
            "ROUGE2_precision: 0.09\n",
            "ROUGE2_recall: 0.08\n",
            "ROUGE2_F1: 0.08\n",
            "ROUGEL_precision: 0.24\n",
            "ROUGEL_recall: 0.2\n",
            "ROUGEL_F1: 0.22\n",
            "BERT_precision: 0.39\n",
            "BERT_recall: 0.43\n",
            "BERT_F1: 0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.23\n",
            "ROUGE1_precision: 0.17\n",
            "ROUGE1_recall: 0.35\n",
            "ROUGE1_F1: 0.23\n",
            "ROUGE2_precision: 0.05\n",
            "ROUGE2_recall: 0.11\n",
            "ROUGE2_F1: 0.07\n",
            "ROUGEL_precision: 0.1\n",
            "ROUGEL_recall: 0.2\n",
            "ROUGEL_F1: 0.13\n",
            "BERT_precision: 0.18\n",
            "BERT_recall: 0.27\n",
            "BERT_F1: 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.25\n",
            "ROUGE1_precision: 0.49\n",
            "ROUGE1_recall: 0.35\n",
            "ROUGE1_F1: 0.41\n",
            "ROUGE2_precision: 0.08\n",
            "ROUGE2_recall: 0.06\n",
            "ROUGE2_F1: 0.07\n",
            "ROUGEL_precision: 0.23\n",
            "ROUGEL_recall: 0.17\n",
            "ROUGEL_F1: 0.19\n",
            "BERT_precision: 0.38\n",
            "BERT_recall: 0.28\n",
            "BERT_F1: 0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.19\n",
            "ROUGE1_precision: 0.23\n",
            "ROUGE1_recall: 0.25\n",
            "ROUGE1_F1: 0.24\n",
            "ROUGE2_precision: 0.04\n",
            "ROUGE2_recall: 0.04\n",
            "ROUGE2_F1: 0.04\n",
            "ROUGEL_precision: 0.15\n",
            "ROUGEL_recall: 0.17\n",
            "ROUGEL_F1: 0.16\n",
            "BERT_precision: 0.25\n",
            "BERT_recall: 0.35\n",
            "BERT_F1: 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.37\n",
            "ROUGE1_precision: 0.39\n",
            "ROUGE1_recall: 0.44\n",
            "ROUGE1_F1: 0.41\n",
            "ROUGE2_precision: 0.23\n",
            "ROUGE2_recall: 0.27\n",
            "ROUGE2_F1: 0.25\n",
            "ROUGEL_precision: 0.26\n",
            "ROUGEL_recall: 0.3\n",
            "ROUGEL_F1: 0.28\n",
            "BERT_precision: 0.52\n",
            "BERT_recall: 0.6\n",
            "BERT_F1: 0.56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.18\n",
            "ROUGE1_precision: 0.22\n",
            "ROUGE1_recall: 0.24\n",
            "ROUGE1_F1: 0.23\n",
            "ROUGE2_precision: 0.0\n",
            "ROUGE2_recall: 0.0\n",
            "ROUGE2_F1: 0.0\n",
            "ROUGEL_precision: 0.17\n",
            "ROUGEL_recall: 0.18\n",
            "ROUGEL_F1: 0.18\n",
            "BERT_precision: 0.25\n",
            "BERT_recall: 0.22\n",
            "BERT_F1: 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.14\n",
            "ROUGE1_precision: 0.41\n",
            "ROUGE1_recall: 0.29\n",
            "ROUGE1_F1: 0.34\n",
            "ROUGE2_precision: 0.08\n",
            "ROUGE2_recall: 0.05\n",
            "ROUGE2_F1: 0.06\n",
            "ROUGEL_precision: 0.31\n",
            "ROUGEL_recall: 0.21\n",
            "ROUGEL_F1: 0.25\n",
            "BERT_precision: 0.35\n",
            "BERT_recall: 0.31\n",
            "BERT_F1: 0.33\n",
            "Score Summary:\n",
            "BLEU: 0.06\n",
            "METEOR: 0.21\n",
            "ROUGE1_precision: 0.47\n",
            "ROUGE1_recall: 0.31\n",
            "ROUGE1_F1: 0.38\n",
            "ROUGE2_precision: 0.08\n",
            "ROUGE2_recall: 0.05\n",
            "ROUGE2_F1: 0.06\n",
            "ROUGEL_precision: 0.32\n",
            "ROUGEL_recall: 0.21\n",
            "ROUGEL_F1: 0.25\n",
            "BERT_precision: 0.41\n",
            "BERT_recall: 0.29\n",
            "BERT_F1: 0.34\n",
            "Score Summary:\n",
            "BLEU: 0.28\n",
            "METEOR: 0.68\n",
            "ROUGE1_precision: 0.41\n",
            "ROUGE1_recall: 0.79\n",
            "ROUGE1_F1: 0.54\n",
            "ROUGE2_precision: 0.33\n",
            "ROUGE2_recall: 0.67\n",
            "ROUGE2_F1: 0.44\n",
            "ROUGEL_precision: 0.35\n",
            "ROUGEL_recall: 0.68\n",
            "ROUGEL_F1: 0.46\n",
            "BERT_precision: 0.49\n",
            "BERT_recall: 0.75\n",
            "BERT_F1: 0.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.38\n",
            "ROUGE1_precision: 0.38\n",
            "ROUGE1_recall: 0.44\n",
            "ROUGE1_F1: 0.41\n",
            "ROUGE2_precision: 0.08\n",
            "ROUGE2_recall: 0.09\n",
            "ROUGE2_F1: 0.08\n",
            "ROUGEL_precision: 0.23\n",
            "ROUGEL_recall: 0.26\n",
            "ROUGEL_F1: 0.24\n",
            "BERT_precision: 0.3\n",
            "BERT_recall: 0.34\n",
            "BERT_F1: 0.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.24\n",
            "ROUGE1_precision: 0.3\n",
            "ROUGE1_recall: 0.38\n",
            "ROUGE1_F1: 0.33\n",
            "ROUGE2_precision: 0.04\n",
            "ROUGE2_recall: 0.05\n",
            "ROUGE2_F1: 0.04\n",
            "ROUGEL_precision: 0.21\n",
            "ROUGEL_recall: 0.27\n",
            "ROUGEL_F1: 0.24\n",
            "BERT_precision: 0.32\n",
            "BERT_recall: 0.33\n",
            "BERT_F1: 0.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.22\n",
            "ROUGE1_precision: 0.35\n",
            "ROUGE1_recall: 0.39\n",
            "ROUGE1_F1: 0.37\n",
            "ROUGE2_precision: 0.08\n",
            "ROUGE2_recall: 0.09\n",
            "ROUGE2_F1: 0.09\n",
            "ROUGEL_precision: 0.18\n",
            "ROUGEL_recall: 0.2\n",
            "ROUGEL_F1: 0.19\n",
            "BERT_precision: 0.4\n",
            "BERT_recall: 0.45\n",
            "BERT_F1: 0.43\n",
            "Score Summary:\n",
            "BLEU: 0.04\n",
            "METEOR: 0.16\n",
            "ROUGE1_precision: 0.5\n",
            "ROUGE1_recall: 0.25\n",
            "ROUGE1_F1: 0.33\n",
            "ROUGE2_precision: 0.1\n",
            "ROUGE2_recall: 0.05\n",
            "ROUGE2_F1: 0.07\n",
            "ROUGEL_precision: 0.33\n",
            "ROUGEL_recall: 0.17\n",
            "ROUGEL_F1: 0.22\n",
            "BERT_precision: 0.39\n",
            "BERT_recall: 0.33\n",
            "BERT_F1: 0.36\n",
            "Score Summary:\n",
            "BLEU: 0.14\n",
            "METEOR: 0.5\n",
            "ROUGE1_precision: 0.35\n",
            "ROUGE1_recall: 0.75\n",
            "ROUGE1_F1: 0.48\n",
            "ROUGE2_precision: 0.2\n",
            "ROUGE2_recall: 0.43\n",
            "ROUGE2_F1: 0.27\n",
            "ROUGEL_precision: 0.25\n",
            "ROUGEL_recall: 0.54\n",
            "ROUGEL_F1: 0.35\n",
            "BERT_precision: 0.42\n",
            "BERT_recall: 0.56\n",
            "BERT_F1: 0.48\n",
            "Score Summary:\n",
            "BLEU: 0.05\n",
            "METEOR: 0.27\n",
            "ROUGE1_precision: 0.31\n",
            "ROUGE1_recall: 0.37\n",
            "ROUGE1_F1: 0.34\n",
            "ROUGE2_precision: 0.09\n",
            "ROUGE2_recall: 0.1\n",
            "ROUGE2_F1: 0.1\n",
            "ROUGEL_precision: 0.14\n",
            "ROUGEL_recall: 0.16\n",
            "ROUGEL_F1: 0.15\n",
            "BERT_precision: 0.36\n",
            "BERT_recall: 0.27\n",
            "BERT_F1: 0.32\n",
            "Score Summary:\n",
            "BLEU: 0.26\n",
            "METEOR: 0.43\n",
            "ROUGE1_precision: 0.72\n",
            "ROUGE1_recall: 0.55\n",
            "ROUGE1_F1: 0.63\n",
            "ROUGE2_precision: 0.39\n",
            "ROUGE2_recall: 0.3\n",
            "ROUGE2_F1: 0.34\n",
            "ROUGEL_precision: 0.45\n",
            "ROUGEL_recall: 0.34\n",
            "ROUGEL_F1: 0.39\n",
            "BERT_precision: 0.57\n",
            "BERT_recall: 0.51\n",
            "BERT_F1: 0.54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.11\n",
            "ROUGE1_precision: 0.33\n",
            "ROUGE1_recall: 0.21\n",
            "ROUGE1_F1: 0.26\n",
            "ROUGE2_precision: 0.03\n",
            "ROUGE2_recall: 0.02\n",
            "ROUGE2_F1: 0.02\n",
            "ROUGEL_precision: 0.22\n",
            "ROUGEL_recall: 0.14\n",
            "ROUGEL_F1: 0.17\n",
            "BERT_precision: 0.31\n",
            "BERT_recall: 0.24\n",
            "BERT_F1: 0.28\n",
            "Score Summary:\n",
            "BLEU: 0.04\n",
            "METEOR: 0.22\n",
            "ROUGE1_precision: 0.62\n",
            "ROUGE1_recall: 0.31\n",
            "ROUGE1_F1: 0.41\n",
            "ROUGE2_precision: 0.11\n",
            "ROUGE2_recall: 0.05\n",
            "ROUGE2_F1: 0.07\n",
            "ROUGEL_precision: 0.41\n",
            "ROUGEL_recall: 0.21\n",
            "ROUGEL_F1: 0.28\n",
            "BERT_precision: 0.38\n",
            "BERT_recall: 0.27\n",
            "BERT_F1: 0.33\n",
            "Score Summary:\n",
            "BLEU: 0.28\n",
            "METEOR: 0.68\n",
            "ROUGE1_precision: 0.45\n",
            "ROUGE1_recall: 0.74\n",
            "ROUGE1_F1: 0.56\n",
            "ROUGE2_precision: 0.37\n",
            "ROUGE2_recall: 0.61\n",
            "ROUGE2_F1: 0.46\n",
            "ROUGEL_precision: 0.29\n",
            "ROUGEL_recall: 0.47\n",
            "ROUGEL_F1: 0.36\n",
            "BERT_precision: 0.3\n",
            "BERT_recall: 0.6\n",
            "BERT_F1: 0.43\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.19\n",
            "ROUGE1_precision: 0.27\n",
            "ROUGE1_recall: 0.26\n",
            "ROUGE1_F1: 0.27\n",
            "ROUGE2_precision: 0.03\n",
            "ROUGE2_recall: 0.03\n",
            "ROUGE2_F1: 0.03\n",
            "ROUGEL_precision: 0.15\n",
            "ROUGEL_recall: 0.15\n",
            "ROUGEL_F1: 0.15\n",
            "BERT_precision: 0.32\n",
            "BERT_recall: 0.31\n",
            "BERT_F1: 0.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.14\n",
            "ROUGE1_precision: 0.27\n",
            "ROUGE1_recall: 0.24\n",
            "ROUGE1_F1: 0.26\n",
            "ROUGE2_precision: 0.0\n",
            "ROUGE2_recall: 0.0\n",
            "ROUGE2_F1: 0.0\n",
            "ROUGEL_precision: 0.12\n",
            "ROUGEL_recall: 0.11\n",
            "ROUGEL_F1: 0.12\n",
            "BERT_precision: 0.23\n",
            "BERT_recall: 0.21\n",
            "BERT_F1: 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.21\n",
            "ROUGE1_precision: 0.39\n",
            "ROUGE1_recall: 0.27\n",
            "ROUGE1_F1: 0.32\n",
            "ROUGE2_precision: 0.1\n",
            "ROUGE2_recall: 0.07\n",
            "ROUGE2_F1: 0.08\n",
            "ROUGEL_precision: 0.26\n",
            "ROUGEL_recall: 0.18\n",
            "ROUGEL_F1: 0.21\n",
            "BERT_precision: 0.42\n",
            "BERT_recall: 0.36\n",
            "BERT_F1: 0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.14\n",
            "ROUGE1_precision: 0.44\n",
            "ROUGE1_recall: 0.23\n",
            "ROUGE1_F1: 0.3\n",
            "ROUGE2_precision: 0.03\n",
            "ROUGE2_recall: 0.02\n",
            "ROUGE2_F1: 0.02\n",
            "ROUGEL_precision: 0.22\n",
            "ROUGEL_recall: 0.12\n",
            "ROUGEL_F1: 0.15\n",
            "BERT_precision: 0.34\n",
            "BERT_recall: 0.32\n",
            "BERT_F1: 0.33\n",
            "Score Summary:\n",
            "BLEU: 0.17\n",
            "METEOR: 0.45\n",
            "ROUGE1_precision: 0.38\n",
            "ROUGE1_recall: 0.62\n",
            "ROUGE1_F1: 0.47\n",
            "ROUGE2_precision: 0.21\n",
            "ROUGE2_recall: 0.35\n",
            "ROUGE2_F1: 0.26\n",
            "ROUGEL_precision: 0.28\n",
            "ROUGEL_recall: 0.46\n",
            "ROUGEL_F1: 0.34\n",
            "BERT_precision: 0.44\n",
            "BERT_recall: 0.54\n",
            "BERT_F1: 0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score Summary:\n",
            "BLEU: 0.0\n",
            "METEOR: 0.19\n",
            "ROUGE1_precision: 0.42\n",
            "ROUGE1_recall: 0.22\n",
            "ROUGE1_F1: 0.29\n",
            "ROUGE2_precision: 0.08\n",
            "ROUGE2_recall: 0.04\n",
            "ROUGE2_F1: 0.05\n",
            "ROUGEL_precision: 0.19\n",
            "ROUGEL_recall: 0.1\n",
            "ROUGEL_F1: 0.13\n",
            "BERT_precision: 0.34\n",
            "BERT_recall: 0.18\n",
            "BERT_F1: 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_JP_BART.to_csv(\"scores_JP_BART.csv\")\n",
        "df_JP_BART_ft.to_csv(\"scores_JP_BART_ft.csv\")\n",
        "df_ES_BART.to_csv(\"scores_ES_BART.csv\")\n",
        "df_ES_BART_ft.to_csv(\"scores_ES_BART_ft.csv\")\n"
      ],
      "metadata": {
        "id": "13tKc5aE3bwn"
      },
      "id": "13tKc5aE3bwn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "evaluator_casaInternational"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
